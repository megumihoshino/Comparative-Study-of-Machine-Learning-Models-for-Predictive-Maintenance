# -*- coding: utf-8 -*-
"""Comparative_Study_of_Machine_Learning_Models_for_Predictive_Maintenance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G05CueVGrSg-VJLMcPXK39-M4oz727_2
"""

# Commented out IPython magic to ensure Python compatibility.
#import all library

import csv
import io
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.image as img
import tensorflow as tf

from imblearn.over_sampling import SMOTE
from collections import Counter

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

# %matplotlib inline

pred_main = pd.read_csv('/content/sample_data/ai 2020.csv')
pred_main

import warnings
warnings.filterwarnings("ignore")

pred_main[pred_main["Machine failure"] ==1]

"""**DATA PREPROCESSING**"""

pred_main.info()

pred_main.isnull().sum()

pred_main.duplicated().sum()

pred_main.dtypes

pred_main.nunique()

pred_main['Type'].value_counts()

"""ada 6000 data LOW, lalu 2997 data medium, dan 1003 high"""

pred_main.drop(columns = ['UDI', 'Product ID'], inplace = True)

"""**FEATURE ENGINEERING**

membuat fitur baru, yaitu **"temperature difference"**
dimana fitur tersebut kita dapatkan dari pengurangan antara *"process temperature - air temperature"*
"""

pred_main['temperature difference'] = pred_main['Process temperature [K]'] - pred_main['Air temperature [K]']



"""Membuat fitur baru: **mechanical power**

rumusnya: *torque* * *rotational speed*


"""

pred_main['mechanical power'] = np.round((pred_main['Torque [Nm]'] * pred_main['Rotational speed [rpm]']*2*np.pi)/60)

pred_main

"""**DESKRIPSI STATISTIK**"""

pred_main.describe().T

"""**EDA (EXPLORATORY DATA ANALYSIS)**

*1.1 PLOTTING DISTRIBUSI TIPE2 MESIN*

Plotting ini berfungsi untuk agar kita bisa melihat mana saja tipe mesin yang tergolong Low (L), Medium (M), atau High (H)
"""

plt.figure(figsize=(12,8))
sns.countplot(x='Type', data=pred_main, hue = 'Type')
plt.title('Distribution Tipe-tipe Mesin', fontsize = 16, fontweight = 'bold')
plt.xlabel('Tipe Mesin', fontsize = 12)
plt.ylabel('Jumlah', fontsize = 12)
plt.show()

"""***1.2 Visualisasi Distribusi "Failure" terhadap Tipe-tipe Produk***"""

plt.figure(figsize = (12, 8))
sns.countplot(x = 'Type', hue = 'Machine failure', data = pred_main)
plt.title('Distribusi Failure terhadap Tipe-tipe Produk', fontsize = 16, fontweight = 'bold')
plt.xlabel('Tipe Mesin', fontsize = 12)
plt.ylabel('Jumlah', fontsize = 12)
plt.legend(title = 'Failure', loc = 'upper right')
plt.show()

"""***1.3 PLOTTING DISTRIBUSI FITUR-FITUR UNTUK MENGAMATI POLA ATAU ANOMALI***"""

cols = ['Torque [Nm]', 'Rotational speed [rpm]', 'temperature difference', 'mechanical power']

for col in cols:
  fig, axes = plt.subplots(1,2, figsize= (14,8))

  sns.histplot(data = pred_main, x = col, ax = axes[0])
  axes[0].set_title(f"{col} Distribution")

  sns.boxplot(data = pred_main, x = col, ax = axes[1])
  axes[1].set_title(f"{col} Outlier Check")

  plt.tight_layout()
  plt.show()

"""***1.4 PAIRPLOT HUBUNGAN ANTAR FITUR (PAIRPLOT FEATURE RELATIONSHIP)***"""

sns.pairplot(pred_main[['Torque [Nm]', 'Rotational speed [rpm]', 'temperature difference', 'mechanical power', 'Machine failure']], hue = 'Machine failure')
plt.show()

"""***1.5 KORELASI ANTAR FITUR***"""

corr_matrix = pred_main.corr(numeric_only = True)
plt.figure(figsize = (12,8))
sns.heatmap(
    corr_matrix,
    annot = True,
    linewidths= 0.5,
    fmt = '.2f',
    cmap = 'coolwarm'
)

target = pred_main.iloc[:,[6,7,8,9,10,11]]
target_mat = target.corr()
sns.heatmap(
    target_mat,
    annot = True,
    linewidths = 0.5,
    fmt = '.2f',
    cmap = 'coolwarm'
)

"""Tool wear failure (TWF), heat dissipation failure (HDF),power failure (PWF),overstrain failure (OSF) and random failures (RNF) shows more positive correlation with target variable i.e. machine failure. Thus dropping columns 'TWF','HDF','PWF','OSF','RNF'.

"""

pred_main.drop(columns = ['TWF','HDF','PWF','OSF','RNF'], inplace = True)

pred_main.sample(3)

"""***1.6 ENCODING KOLOM***"""

from sklearn.preprocessing import LabelEncoder
pred_main['Type'] = LabelEncoder().fit_transform(pred_main['Type'])

"""***1.7 FEATURE SCALING***"""

scale = StandardScaler()
data = pd.DataFrame(scale.fit_transform(pred_main), columns=pred_main.columns, index = pred_main.index)

data.sample(15)

"""***1.8 SPLITTING DATA KE BENTUK FITUR X DAN TARGET Y***"""

Y = pred_main.pop("Machine failure")
X = pred_main

X

Y

"""***1.9 BERHADAPAN DENGAN DATA YANG TIDAK SEIMBANG (DEALING WITH IMBALANCED DATA)***"""

from collections import Counter
counts = Counter(Y)
print(counts)

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X,Y)

from collections import Counter
counts = Counter(y_resampled)
print(counts)

"""***1.10 TRAIN TEST SPLIT***"""

X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, y_resampled, test_size = 0.1)

from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

models = {
    'Logistic Regression': LogisticRegression(),
    'Logistic Regression CV': LogisticRegressionCV(),
    'SGD Classifier': SGDClassifier(),
    'Random Forest Classifier': RandomForestClassifier(),
    'Gradient Boosting Classifier': GradientBoostingClassifier(),
    'AdaBoost Classifier': AdaBoostClassifier(),
    'Bagging Classifier': BaggingClassifier(),
    'Decision Tree Classifier': DecisionTreeClassifier(),
    'Support Vector Machine': SVC(),
    'K-Nearest Neighbors': KNeighborsClassifier()
}

def evaluate_model(X_train, X_test, Y_train, Y_test):
  result=[]
  for name, model in models.items():
    model.fit(X_train, Y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(Y_test, y_pred)
    result.append((name, accuracy))

  result.sort(key = lambda x: x[1], reverse = True)
  return result

results = evaluate_model(X_train, X_test, Y_train, Y_test)
print("Perfoma Model: ")
for name, accuracy in results:
  print(f"{name}: {accuracy: .3f}")

"""dari pengujian model ini kita bisa lihat kalau model RANDOM FOREST menghasilkan nilai performa yang paling tinggi diantara model2 tsb"""

rf = RandomForestClassifier(class_weight = 'balanced')

rf.fit(X_train, Y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(Y_test, y_pred)
print(f"Akurasi: {accuracy: .3f}")

"""Lalu kita cek performa model RF menggunakan akurasi, precision, recall dan skor F-1"""

from sklearn.metrics import(
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
    roc_auc_score,
    RocCurveDisplay,
    precision_recall_curve,
    PrecisionRecallDisplay,
)

def evaluate_model(model, X_test, y_test, model_name = "MODEL"):
  y_pred = model.predict(X_test)
  y_prob = model.predict_proba(X_test)[:, 1]

  print(f"Classification Report for {model_name}:")
  print(classification_report(y_test, y_pred))

  cm = confusion_matrix(y_test, y_pred)
  disp = ConfusionMatrixDisplay(confusion_matrix = cm)
  disp.plot(cmap = 'Blues')
  plt.title(f"Confusion Matrix for {model_name}")
  plt.show

  roc_auc = roc_auc_score(y_test, y_prob)
  RocCurveDisplay.from_predictions(y_test, y_prob)
  plt.title(f"ROC Curve for {model_name}")
  plt.show()

  precision, recall_score, _ = precision_recall_curve(y_test, y_prob)
  PrecisionRecallDisplay(precision = precision, recall = recall_score).plot()
  plt.title(f"Precision-Recall Curve for {model_name}")
  plt.show()

evaluate_model(rf, X_test, Y_test, model_name = "RANDOM FOREST")

importances = rf.feature_importances_
feature_names = X.columns

feature_imp_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by = 'Importance', ascending = False)

plt.figure(figsize = (12,8))
sns.barplot(x = 'Importance', y = 'Feature', data = feature_imp_df, palette = 'viridis')
plt.title('Feature Importance', fontsize = 16, fontweight = 'bold')
plt.tight_layout()
plt.show